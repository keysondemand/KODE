import sys, json, re, time, csv
import os, threading, socket, ast
import numpy as np

sys.path += ['./', '../', '../../']

from charm.core.engine.util import *
from OpenSSL import SSL, crypto
from sys import argv
from time import sleep
from operator import add

from conf.connectionconfig import *
from conf.groupparam import *
from util.connectionutils import *
from util.transactionbroadcast import *
from util.nizk import *

from secretsharing.shamir.shamirsharing import *
from secretsharing.blackbox.bbssutil.rhocommit import *
from secretsharing.combinatorial.cssutils.css_commitment import *

debug = 0
broadcast_counter = 0

my_rcvd_shares = {}
my_rcvd_shares_dash = {}
my_rcvd_shares_strings = {}
my_rcvd_shares_dash_strings = {}

peer_share_commits = {}
peer_dlog_commits = {}

generated_shares = {}

complaints = {}
records = {}
nizks = {}

accused_nodes = []
nodes_verification_failed = []

QualifiedSet = []
DisqualifiedSet = []

M = []
N_NODES = 0
MALICIOUS = 0
node_share_index = {}

tx_count = 0
epoch = 0

SECRET_SHARING = ""


def DPRINT(*args, **kwargs):
    if debug:
        print(*args, **kwargs)


def deserializeElements(objects):
    object_byte_strings = re.findall(r"'(.*?)'", objects, re.DOTALL)
    object_strings = [str.encode(a) for a in object_byte_strings]
    elements = [group.deserialize(a) for a in object_strings]
    return elements


def serverSock(MY_IP, MY_PORT, nid):
    print("server socket")
    print("N_NODES", N_NODES)
    all_client_threads = []
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind(('', MY_PORT))
    s.listen(N_NODES)

    t = threading.currentThread()
    while getattr(t, "data_receive", True):
        try:
            peer_con, peer_addr = s.accept()

            handle_peer_thread = threading.Thread(target=handle_peer, args=(peer_con, nid))
            handle_peer_thread.start()

            all_client_threads.append(handle_peer_thread)

        except KeyboardInterrupt:
            print("[!] Keyboard Interrupted!")
            s.shutdown(socket.SHUT_RDWR)
            s.close()
            for thread in all_client_threads:
                thread.join()
                break
        except Exception as e:
            print(e)

    DPRINT("***Exiting the loop")

    for thread in all_client_threads:
        thread.join()
    return


def handle_peer(peer_con, nid):
    data_received = recv_data(peer_con)

    if not data_received:
        return

    # Send ACK
    peer_con.sendall(b"ACK")
    peer_con.close()

    data_received = json.loads(data_received)
    pid = data_received["my_id"]

    if data_received["msg_type"] == "HELLO":
        DPRINT("Hello received from:", pid)

    if data_received["msg_type"] == "SHARES":
        DPRINT("Received Shares")
        receive_shares(nid, pid, data_received)

    if data_received["msg_type"] == "DLogNizkKey":
        DPRINT("DLogNizk")
        handleDlogNizk(pid, data_received)
    return


def sendId2peers(nid):
    data_to_send = {'msg_type': "HELLO",
                    'my_id': nid
                    }
    data_to_send = json.dumps(data_to_send)

    for pid in range(N_NODES):
        if nid != pid:
            DPRINT("Sending Hello to:", pid)
            send2Node(nid, pid, data_to_send)


def sendShareCommits2Peers(M, nid):

    global tx_count
    tx_count = tx_count + 1

    t = None

    S, S_dash, rho_commits, rho_commit_strings, RHO, RHO_dash, dlog_commits, dlog_commit_strings = ([] for i in range(8))

    if SECRET_SHARING == "BBSS":
        print("M-shape", M.shape)
        S, S_dash, rho_commits, rho_commit_strings, RHO, RHO_dash, dlog_commits, dlog_commit_strings = rhoCommit(M)
    elif SECRET_SHARING == "CSS":
        # FOR CSS, there is no RHO
        S, S_dash, rho_commits, rho_commit_strings, RHO, RHO_dash, dlog_commits, dlog_commit_strings = cssCommit(N_NODES)
    elif SECRET_SHARING == "SHAMIR":
        S, S_dash, rho_commits, rho_commit_strings, RHO, RHO_dash, dlog_commits, dlog_commit_strings = shamirShareGenCommit(
            N_NODES)

    querykey = "ID" + str(nid) + "tx_count" + str(tx_count) + "epoch" + str(epoch) + str(
        time.strftime("%Y-%m-%d-%H-%M"))

    rho_strings = []
    rho_dash_strings = []
    for i in range(len(RHO)):
        rho_strings.append(group.serialize(RHO[i]))
        rho_dash_strings.append(group.serialize(RHO_dash[i]))

    # Save random shares generated by self
    generated_shares['PedersenCommitStrings'] = str(rho_commit_strings)
    generated_shares['RHOStrings'] = str(rho_strings)
    generated_shares['RHOS'] = rho_strings
    generated_shares['RHODashStrings'] = str(rho_dash_strings)
    generated_shares['DlogCommitStrings'] = str(dlog_commit_strings)

    generated_shares['DlogCom'] = dlog_commits
    generated_shares['RHO'] = RHO
    generated_shares['RHODash'] = RHO_dash
    generated_shares['PederCom'] = rho_commits

    if SECRET_SHARING == "CSS":
        generated_shares['S'] = S
        generated_shares['S_dash'] = S_dash


    # Broadcast using Tendermint
    tobdx = {
        'my_id': nid,
        'BroadcastCommit': str(rho_commit_strings),
        'epoch': 0
    }
    broadcast(tobdx, querykey)

    DPRINT("S", S)
    DPRINT(rho_commits)
    DPRINT(RHO)
    DPRINT("node_share_index:", node_share_index)
    DPRINT("node_share_index.keys():", node_share_index.keys())

    for pid in range(N_NODES):

        if nid == pid:
            continue

        records[pid] = {}

        DPRINT("pid:", pid)
        DPRINT("node_share_index[pid]", node_share_index[str(pid)])
        shares = []
        shares_dash = []

        shares_strings = []
        shares_dash_strings = []

        for index in node_share_index[str(pid)]:
            shares.append(S[index])
            shares_dash.append(S_dash[index])

            shares_strings.append(group.serialize(S[index]))
            shares_dash_strings.append(group.serialize(S_dash[index]))

        data_to_send = {
            'msg_type': "SHARES",
            'my_id': nid,
            'key': querykey,
            'share_strings': str(shares_strings),
            'share_dash_strings': str(shares_dash_strings)
        }
        data_to_send = json.dumps(data_to_send)

        DPRINT(data_to_send)
        try:
            DPRINT("Sending shares to node id:", pid)
            send2Node(nid, pid, data_to_send)

        except Exception as e:
            print("Exception while sending shares:", e)


def receive_shares(nid, pid, share_rcvd):
    try:
        begin_receive_handling = time.process_time()

        # Store in strings from for complaint phase
        my_rcvd_shares_strings[pid] = share_rcvd['share_strings']
        my_rcvd_shares_dash_strings[pid] = share_rcvd['share_dash_strings']

        # Deserialize to obtain the values
        my_rcvd_shares[pid] = deserializeElements(share_rcvd['share_strings'])
        my_rcvd_shares_dash[pid] = deserializeElements(share_rcvd['share_dash_strings'])

        query_key = share_rcvd['key']
        # Query from Tendermint

        query_retries = 0
        while query_retries < 10:
            try:
                queried_result = query(query_key)
            except:
                sleep(1)
                query_retries += 1
            else:
                break
        DPRINT("queried_result:", queried_result)

        commits = queried_result['BroadcastCommit']
        final_commits = deserializeElements(commits)

        peer_share_commits[pid] = final_commits

    except Exception as e:
        print(e)
    verify_received_shares(nid, pid)


def verify_received_shares(nid, pid):

    try:

        peer_rho_commits = peer_share_commits[pid]
        shares_rcvd = my_rcvd_shares[pid]
        shares_dash_rcvd = my_rcvd_shares_dash[pid]

        if SECRET_SHARING == "BBSS" or SECRET_SHARING == "SHAMIR":
            M_my_rows = M[node_share_index[str(nid)]]
            DPRINT("My M rows:", M_my_rows)

            if len(M_my_rows) != len(shares_rcvd):
                print("Error!: The number of nodes' rows in M and number of shares received are not same")
        verified_shares_counter = 0

        # Check each received share
        for i in range(len(shares_rcvd)):
            DPRINT("peer_rho_commits", peer_rho_commits)
            computed_share_commitment = (g ** shares_rcvd[i]) * (h ** shares_dash_rcvd[i])
            commitment_product = unity

            if SECRET_SHARING == "BBSS":

                for j in range(len(M_my_rows[i])):
                    if M_my_rows[i][j] == 1:
                        commitment_product = commitment_product * peer_rho_commits[j]

                if (computed_share_commitment == commitment_product):
                    DPRINT("Share[", i, "] Verified")
                    verified_shares_counter += 1

            if SECRET_SHARING == "SHAMIR":

                for j in range(len(M_my_rows[i])):
                    b = group.init(ZR, int(M_my_rows[i][j]))
                    commitment_product = commitment_product * (peer_rho_commits[j] ** b)

                if computed_share_commitment == commitment_product:
                    DPRINT("Share[", i, "] Verified")
                    verified_shares_counter += 1

            if SECRET_SHARING == "CSS":

                if computed_share_commitment in peer_rho_commits:
                    DPRINT("Share[", i, "] Verified")
                    verified_shares_counter += 1

        if verified_shares_counter == len(shares_rcvd):
            DPRINT("Great, all shares verified for peer ID:", pid)

        else:
            print("Something looks fishy, raising a complaint against peer ID:", pid)
            nodes_verification_failed.append(pid)
    except Exception as e:
        print("Error during verification of shares:", e)


def broadcastDLogNIZK(nid):
    share_not_generated = 1
    while share_not_generated:
        try:
            if SECRET_SHARING == "BBSS" or SECRET_SHARING == "SHAMIR":
                dlog_commit = generated_shares['DlogCom'][0]
            elif SECRET_SHARING == "CSS":
                dlog_commits = generated_shares['DlogCom']
        except:
            sleep(0.2)
        else:
            share_not_generated = 0

    # dlog_commit             = generated_shares['DlogCom'][0]
    if SECRET_SHARING == "BBSS" or SECRET_SHARING == "SHAMIR":
        pedersen_commit = generated_shares['PederCom'][0]
        rho_zero = generated_shares['RHO'][0]
        rho_dash_zero = generated_shares['RHODash'][0]
        dlog_commit_to_send = [group.serialize(dlog_commit)]
        zkp_vec = nizkpok_vec([dlog_commit], [pedersen_commit], [rho_zero], [rho_dash_zero])

    elif SECRET_SHARING == "CSS":
        pedersen_commits = generated_shares['PederCom']
        shares = generated_shares['S']
        shares_dash = generated_shares['S_dash']
        dlog_commit_to_send = generated_shares['DlogCommitStrings'] 
        zkp_vec = nizkpok_vec(dlog_commits, pedersen_commits, shares, shares_dash)

    tobdx = {
        'msg_type': 'DLOGNIZK',
        'my_id': nid,
        'DLogStrings': str(dlog_commit_to_send),
        'NIZK': str(zkp_vec)
    }

    global tx_count
    global epoch
    tx_count = tx_count + 1
    querykey = "NIZKID" + str(nid) + "tx_count" + str(tx_count) + "epoch" + str(epoch) + str(
        time.strftime("%Y-%m-%d-%H-%M"))

    # Tendermint broadcast
    broadcast(tobdx, querykey)

    data_to_send = {
        'msg_type': 'DLogNizkKey',
        'my_id': nid,
        'key': querykey
    }
    data_to_send = json.dumps(data_to_send)

    # Individual key send
    for pid in range(N_NODES):
        if pid == nid:
            continue
        try:
            DPRINT("Sending Nizk query key to node id:", pid)
            send2Node(nid, pid, data_to_send)
        except Exception as e:
            print("Error in sending DLogNizk Query Key to node-", pid, e)


def handleDlogNizk(pid, broadcastedDlogNizk):
    # nizk_nid = broadcastedDlogNizk['my_id']
    nizk_querykey = broadcastedDlogNizk['key']

    ###### query from Tendermint
    nizks[pid] = query(nizk_querykey)

    verifyDlogNizk(nizks[pid], pid)
    return


def verifyDlogNizk(nizks, pid):
    DPRINT("nizks received:", nizks)
    nizk_nid = nizks['my_id']
    dlog_strings = nizks['DLogStrings']
    nizk_vec = nizks['NIZK']

    # print("nizk_vec",nizk_vec,"type(nizk_vec):", type(nizk_vec), "nizk_vec[0]", nizk_vec[0])

    nizk_vec = deserializeElements(nizk_vec)
    dlog_commits = deserializeElements(dlog_strings)

    share_not_verified = 1

    # if share is not verified on the other thread yet
    while share_not_verified:
        try:
            pedersen_commits = peer_share_commits[pid]
        except:
            sleep(1)
        else:
            share_not_verified = 0

    # g = group.encode(decoded_g, True)
    # h = group.encode(decoded_h, True)

    DPRINT("Len of pedersen commits:", len(pedersen_commits))
    DPRINT("Len of dlog     commits:", len(dlog_commits))
    DPRINT("Len of nizk_vec:", len(nizk_vec))

    proofs = []
    for i in range(len(nizk_vec) // 3):
        c = nizk_vec[3 * i]
        u1 = nizk_vec[(3 * i) + 1]
        u2 = nizk_vec[(3 * i) + 2]
        DPRINT("\n\nsent proof:", [c, u1, u2])
        proofs.append([c, u1, u2])  # Putting them back as lists, not sure if it is needed

        V1_dash = (g ** u1) * (dlog_commits[i] ** c)

        dlog_commits_inv = dlog_commits[i] ** (-1)
        V2_dash = (h ** u2) * ((pedersen_commits[i] * dlog_commits_inv) ** c)

        c_dash = group.hash((g, h, dlog_commits[i], pedersen_commits[i], V1_dash, V2_dash), ZR)
        c_str = str(c)
        c_str = c_str[:len(c_str) - 30]
        c_dash_str = str(c_dash)
        c_dash_str = c_dash_str[:len(c_dash_str) - 30]

        if group == group571:
            if c_str == c_dash_str:
                print("The NIZK proof is verified")
            else:
                DisqualifiedSet.append(pid)
        else:
            if (c == c_dash):
                DPRINT("The NIZK proof is verified")
            else:
                DisqualifiedSet.append(pid)
